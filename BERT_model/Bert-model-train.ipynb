{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-06-12T14:55:48.100637Z",
     "iopub.status.busy": "2023-06-12T14:55:48.100180Z",
     "iopub.status.idle": "2023-06-12T14:55:48.108351Z",
     "shell.execute_reply": "2023-06-12T14:55:48.107363Z",
     "shell.execute_reply.started": "2023-06-12T14:55:48.100514Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/diseasetreatmentdata/data.json\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T14:56:19.487739Z",
     "iopub.status.busy": "2023-06-12T14:56:19.487385Z",
     "iopub.status.idle": "2023-06-12T14:56:19.495589Z",
     "shell.execute_reply": "2023-06-12T14:56:19.494626Z",
     "shell.execute_reply.started": "2023-06-12T14:56:19.487710Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load JSON file\n",
    "with open(os.path.join(dirname, filename), 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T15:20:27.279236Z",
     "iopub.status.busy": "2023-06-12T15:20:27.278783Z",
     "iopub.status.idle": "2023-06-12T15:37:21.130539Z",
     "shell.execute_reply": "2023-06-12T15:37:21.129538Z",
     "shell.execute_reply.started": "2023-06-12T15:20:27.279199Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./model/tokenizer_config.json',\n",
       " './model/special_tokens_map.json',\n",
       " './model/vocab.txt',\n",
       " './model/added_tokens.json')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Initialize lists to hold our sentences (intents), labels (diseases), and responses\n",
    "sentences = []\n",
    "labels = []\n",
    "responses = []\n",
    "\n",
    "# Fill lists with data from JSON\n",
    "for intent in data[\"intents\"]:\n",
    "    for pattern in intent[\"symptoms\"]:\n",
    "        sentences.append(pattern)\n",
    "        labels.append(intent[\"name\"])\n",
    "        responses.append(intent[\"response\"])\n",
    "\n",
    "# Load the ClinicalBERT model and tokenizer\n",
    "model = BertForSequenceClassification.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\", num_labels=len(set(labels)))\n",
    "tokenizer = BertTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "\n",
    "# Tokenize our sentences\n",
    "inputs = tokenizer(sentences, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "\n",
    "# Encode our labels\n",
    "encoder = LabelEncoder()\n",
    "labels = encoder.fit_transform(labels)\n",
    "\n",
    "# Split the data into training and validation datasets\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(inputs.input_ids, labels, test_size=0.3)\n",
    "\n",
    "# Create TensorDatasets for the training and validation sets\n",
    "train_dataset = TensorDataset(train_inputs, inputs.attention_mask[:len(train_inputs)], torch.tensor(train_labels))\n",
    "validation_dataset = TensorDataset(validation_inputs, inputs.attention_mask[len(train_inputs):], torch.tensor(validation_labels))\n",
    "\n",
    "# Create DataLoaders for the training and validation sets\n",
    "train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=32)\n",
    "validation_dataloader = DataLoader(validation_dataset, sampler=SequentialSampler(validation_dataset), batch_size=32)\n",
    "\n",
    "# Define our optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "epochs = 200\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        labels = labels.to(device)\n",
    "        model.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    \n",
    "model.eval()\n",
    "total_eval_accuracy = 0\n",
    "for batch in validation_dataloader:\n",
    "    input_ids, attention_mask, labels = batch\n",
    "    input_ids = input_ids.to(device)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "    labels = labels.to(device)\n",
    "    with torch.no_grad():        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    correct_predictions = predictions == labels\n",
    "    total_eval_accuracy += correct_predictions.sum().item()\n",
    "\n",
    "model.save_pretrained(\"./model\")\n",
    "tokenizer.save_pretrained(\"./model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T15:38:20.036312Z",
     "iopub.status.busy": "2023-06-12T15:38:20.035939Z",
     "iopub.status.idle": "2023-06-12T15:38:20.042578Z",
     "shell.execute_reply": "2023-06-12T15:38:20.041385Z",
     "shell.execute_reply.started": "2023-06-12T15:38:20.036284Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# Save the encoder\n",
    "with open(os.path.join(os.getcwd(), \"label_encoder.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(encoder, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T15:43:32.772885Z",
     "iopub.status.busy": "2023-06-12T15:43:32.772498Z",
     "iopub.status.idle": "2023-06-12T15:43:57.354471Z",
     "shell.execute_reply": "2023-06-12T15:43:57.353218Z",
     "shell.execute_reply.started": "2023-06-12T15:43:32.772853Z"
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please describe your symptom:  Muscle weakness or spasms\",         \"Blurred or double vision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current confidence level is: 0.04914657026529312\n",
      "Chatbot:  That is a very common symptom, provide me with another symptom you are facing\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please describe your symptom:  \"Fatigue\",         \"Numbness or tingling in the limbs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current confidence level is: 0.09269026666879654\n",
      "You may be suffering from: Sciatica\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "import random\n",
    "\n",
    "with open(os.path.join(os.getcwd(), \"label_encoder.pkl\"), \"rb\") as f:\n",
    "    encoder = pickle.load(f)\n",
    "# Confidence threshold\n",
    "confidence_threshold = 0.062\n",
    "\n",
    "# User's symptoms\n",
    "user_symptoms = \"\"\n",
    "\n",
    "# Create a pipeline for classification\n",
    "classifier = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1)\n",
    "\n",
    "while True:\n",
    "    # User enters a symptom\n",
    "    user_symptom = input(\"Please describe your symptom: \")\n",
    "\n",
    "    # Add symptom to user's symptoms\n",
    "    user_symptoms += \" \" + user_symptom\n",
    "\n",
    "    # Predict the class of the symptoms\n",
    "    result = classifier(user_symptoms)\n",
    "\n",
    "    # Calculate the confidence of the prediction\n",
    "    max_proba = result[0]['score']\n",
    "\n",
    "    print(f\"Current confidence level is: {max_proba}\")\n",
    "\n",
    "    if max_proba >= confidence_threshold:\n",
    "        # Decode the class to get the original label (intent)\n",
    "        class_index = int(result[0]['label'].split(\"_\")[-1])\n",
    "\n",
    "        # Get the disease name from the class index\n",
    "        predicted_disease = encoder.inverse_transform([class_index])[0]\n",
    "\n",
    "        # Output the response\n",
    "        print(f\"You may be suffering from: {predicted_disease}\")\n",
    "        break\n",
    "    else:\n",
    "        common_symptoms_response = [\"Your symptoms are quite common, could you please provide more details or any other symptom?\", \n",
    "                                    \"That is a very common symptom, provide me with another symptom you are facing\",\n",
    "                                    \"That's a quite common symptom for many diseases, provide me with any another symptom you are having?\"]\n",
    "        print(\"Chatbot: \", random.choice(common_symptoms_response))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade accelerate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
